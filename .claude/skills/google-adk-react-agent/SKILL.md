---
name: google-adk-react-agent
description: Build ReAct (Reasoning + Acting) agents using Google ADK. Use this skill when creating agents that need to plan, reason, and execute tools iteratively. Triggers for building LLM agents with Google ADK, implementing Plan-ReAct patterns, creating multi-agent systems, or using PlanReActPlanner.
---

# Google ADK ReAct Agent Builder

Build ReAct agents using Google's Agent Development Kit (ADK).

## Quick Start

```python
from google.adk.agents import LlmAgent
from google.adk.planners import PlanReActPlanner

def my_tool(query: str) -> dict:
    """Tool description for the LLM."""
    return {"result": "..."}

agent = LlmAgent(
    name="react_agent",
    model="gemini-2.0-flash",
    instruction="Your agent instructions here.",
    tools=[my_tool],
    planner=PlanReActPlanner(),
)
```

## Core Components

### 1. LlmAgent
The main agent class. Key parameters:
- `name`: Unique identifier (Python identifier, not "user")
- `model`: LLM model string (e.g., "gemini-2.0-flash", "gemini-1.5-pro")
- `instruction`: System prompt with optional `{state_variable}` placeholders
- `tools`: List of functions or BaseTool instances
- `planner`: PlanReActPlanner() for ReAct behavior
- `sub_agents`: List of child agents for delegation

### 2. PlanReActPlanner (Detailed)

Implements Plan-ReAct pattern with explicit prompt-based planning and structured tags.

#### Tags/Format
```python
PLANNING_TAG = '/*PLANNING*/'      # Initial step-by-step plan
REPLANNING_TAG = '/*REPLANNING*/'  # Plan revision if needed
REASONING_TAG = '/*REASONING*/'    # Observations and next-step reasoning
ACTION_TAG = '/*ACTION*/'          # Tool execution
FINAL_ANSWER_TAG = '/*FINAL_ANSWER*/'  # Final response to user
```

#### Planning Process Flow
1. **PLANNING**: Model creates numbered step-by-step plan
2. **ACTION**: Model executes tool calls
3. **REASONING**: Model summarizes observations, determines next steps
4. **REPLANNING** (optional): If initial plan fails, model revises it
5. **FINAL_ANSWER**: Model provides final response to user

#### System Prompt Generated by PlanReActPlanner

The planner automatically appends this instruction to the LLM request:

```
When answering the question, try to leverage the available tools to gather
the information instead of your memorized knowledge.

Follow this process when answering the question:
(1) first come up with a plan in natural language text format;
(2) Then use tools to execute the plan and provide reasoning between tool
    code snippets to make a summary of current state and next step. Tool
    code snippets and reasoning should be interleaved with each other.
(3) In the end, return one final answer.

Follow this format when answering the question:
(1) The planning part should be under /*PLANNING*/.
(2) The tool code snippets should be under /*ACTION*/, and the reasoning
    parts should be under /*REASONING*/.
(3) The final answer part should be under /*FINAL_ANSWER*/.
```

**Planning Requirements:**
- Plan must answer the user query when followed
- Plan is coherent and covers all aspects of user query
- Plan only involves accessible tools
- Contains decomposed steps as a numbered list
- Each step uses one or multiple available tools
- If initial plan fails, create revised plan under `/*REPLANNING*/`

**Reasoning Requirements:**
- Summarizes current trajectory based on user query and tool outputs
- Based on tool outputs and plan, provides instructions for next steps
- Makes trajectory progress toward final answer

**Final Answer Requirements:**
- Must be precise and follow query formatting requirements
- If query is unanswerable, inform user why and ask for more information

**Tool Code Requirements:**
- Code must be valid self-contained Python snippets
- No imports or references to undefined tools/libraries
- Cannot use parameters not explicitly defined in APIs
- Code should be readable, efficient, and relevant
- Use library name with function name: `vertex_search.search()`
- Never write custom code other than provided tool function calls

#### Response Processing
The planner processes LLM responses to:
- Extract and organize reasoning vs user-facing content
- Mark `/*PLANNING*/`, `/*REASONING*/`, `/*ACTION*/`, `/*REPLANNING*/` text as internal "thought"
- Preserve `/*FINAL_ANSWER*/` content as user-facing output
- Collect and order function calls for execution

### 3. BuiltInPlanner (Alternative)

Uses the model's native thinking capabilities instead of explicit prompting.

```python
from google.adk.planners import BuiltInPlanner
from google.genai import types

agent = LlmAgent(
    name="thinking_agent",
    model="gemini-2.0-flash-thinking-exp",  # Must support thinking
    instruction="Your instructions here.",
    tools=[my_tool],
    planner=BuiltInPlanner(
        thinking_config=types.ThinkingConfig(
            thinking_budget_tokens=1024  # Configure thinking tokens
        )
    ),
)
```

**When to Use:**
- Models with native thinking support (e.g., thinking-exp models)
- Better performance, no explicit prompt overhead
- Less transparent but more efficient

**Comparison:**

| Feature | PlanReActPlanner | BuiltInPlanner |
|---------|------------------|----------------|
| Approach | Explicit prompt-based | Native model thinking |
| Model Support | Works with any model | Requires thinking capability |
| Transparency | Explicit visible stages | Less visible (model internal) |
| Prompt Overhead | Full instruction appended | None |
| Response Processing | Extensive post-processing | None needed |

### 4. Tools
Functions automatically wrapped as tools:
```python
def search(query: str) -> dict:
    """Search for information. (This docstring becomes tool description)

    Args:
        query: The search query.
    """
    return {"results": [...]}
```

Access runtime context via `ToolContext`:
```python
from google.adk.tools import ToolContext

def stateful_tool(data: str, tool_context: ToolContext) -> dict:
    tool_context.state["key"] = "value"  # Modify session state
    return {"result": data}
```

## Common Patterns

### Research Agent
```python
agent = LlmAgent(
    name="researcher",
    model="gemini-1.5-pro",
    instruction="""Research questions thoroughly:
    1. Plan your research approach
    2. Search for information
    3. Synthesize findings
    4. Cite sources""",
    tools=[search_web, read_document],
    planner=PlanReActPlanner(),
)
```

### Multi-Agent with Coordinator
```python
specialist_a = LlmAgent(
    name="data_analyst",
    description="Handles data queries",  # Used for routing
    model="gemini-1.5-pro",
    instruction="Analyze data...",
    tools=[sql_query],
)

specialist_b = LlmAgent(
    name="writer",
    description="Creates documents",
    model="gemini-1.5-pro",
    instruction="Write clearly...",
)

coordinator = LlmAgent(
    name="coordinator",
    model="gemini-1.5-pro",
    instruction="Route to appropriate specialist.",
    sub_agents=[specialist_a, specialist_b],
    planner=PlanReActPlanner(),
)
```

### Structured Output
```python
from pydantic import BaseModel

class Report(BaseModel):
    summary: str
    findings: list[str]

agent = LlmAgent(
    name="reporter",
    model="gemini-1.5-pro",
    output_schema=Report,
    output_key="report",  # Stored in state
    disallow_transfer_to_parent=True,
    disallow_transfer_to_peers=True,
)
```

### Iterative Processing with LoopAgent
```python
from google.adk.agents import LoopAgent
from google.adk.tools import ExitLoopTool

worker = LlmAgent(
    name="worker",
    instruction="Process items. Use exit_loop when done.",
    tools=[process_item, ExitLoopTool()],
    planner=PlanReActPlanner(),
)

loop = LoopAgent(
    name="processor",
    sub_agents=[worker],
    max_iterations=10,
)
```

## Running Agents

```python
from google.adk.apps import App
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService

app = App(name="my_app", root_agent=agent)
runner = Runner(app=app, session_service=InMemorySessionService())

async def run():
    session = await session_service.create_session(
        app_name="my_app", user_id="user_1"
    )
    async for event in runner.run_async(
        session_id=session.id,
        user_id="user_1",
        new_message="User query"
    ):
        if event.content:
            for part in event.content.parts:
                if part.text and not part.thought:
                    print(part.text)
```

## Callbacks

Intercept agent/model/tool lifecycle:

```python
async def before_tool(tool, args, tool_context):
    print(f"Calling {tool.name}")
    return None  # Return dict to skip tool

agent = LlmAgent(
    ...,
    before_model_callback=...,
    after_model_callback=...,
    before_tool_callback=before_tool,
    after_tool_callback=...,
    before_agent_callback=...,
    after_agent_callback=...,
)
```

## Key Imports

```python
from google.adk.agents import LlmAgent, Agent, LoopAgent, SequentialAgent, ParallelAgent
from google.adk.planners import PlanReActPlanner, BuiltInPlanner
from google.adk.tools import FunctionTool, ToolContext, ExitLoopTool
from google.adk.apps import App
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
```

## References

- **LlmAgent API**: See [references/llm_agent_api.md](references/llm_agent_api.md) for full parameter documentation
- **Tools API**: See [references/tools_api.md](references/tools_api.md) for tool creation patterns
- **Planners API**: See [references/planners_api.md](references/planners_api.md) for planner details
- **Examples**: See [references/examples.md](references/examples.md) for complete working examples
